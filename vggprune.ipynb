{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 掛載雲端硬碟"
      ],
      "metadata": {
        "id": "Lk6d9yOhuSkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3NTpFfZGuVSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a1ee89d-7c86-47c4-acb0-6751261d4d78"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##更改檔案所在路徑\n"
      ],
      "metadata": {
        "id": "VEETyGg0uZnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to your own folder !!!\n",
        "%cd /content/drive/MyDrive/EAI_Lab4_2024"
      ],
      "metadata": {
        "id": "Wum2GQmwucfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6ebeff-0eba-499e-8ce4-a5e607429458"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/EAI_Lab4_2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 載入函式庫\n"
      ],
      "metadata": {
        "id": "S9NTZ1VEtbV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "from models import vgg"
      ],
      "metadata": {
        "id": "vCvF-fM0tfsq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##超參數設定"
      ],
      "metadata": {
        "id": "_X_r4dtMuwbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = 'cifar10'\n",
        "TEST_BATCH_SIZE = 1000\n",
        "CUDA = True\n",
        "PRUNE_PERCENT = 0.9 # Change your prune ratio!\n",
        "WEIGHT_PATH = '/content/drive/MyDrive/Colab Notebooks/model_best.pth'\n",
        "PRUNE_PATH = '/content/drive/MyDrive/Colab Notebooks/model_prune.pth'\n"
      ],
      "metadata": {
        "id": "_2NkY0LyuyQh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##載入模型"
      ],
      "metadata": {
        "id": "L7z4dkhJwB4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA = CUDA and torch.cuda.is_available()\n",
        "\n",
        "model = vgg()\n",
        "if CUDA:\n",
        "    model.cuda()\n",
        "\n",
        "if WEIGHT_PATH:\n",
        "    if os.path.isfile(WEIGHT_PATH):\n",
        "        checkpoint = torch.load(WEIGHT_PATH)\n",
        "        best_prec1 = checkpoint['best_prec1']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        print('LOADING CHECKPOINT {} @EPOCH={}, BEST_PREC1={}'.format(WEIGHT_PATH,checkpoint['epoch'],best_prec1))\n",
        "\n",
        "    else:\n",
        "        print(\"NO CHECKPOINT FOUND\")\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "lpIqnhfKwEcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc212472-483c-4c27-a7b1-08077e04b651"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-d2659840b6c9>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(WEIGHT_PATH)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADING CHECKPOINT /content/drive/MyDrive/Colab Notebooks/model_best.pth @EPOCH=46, BEST_PREC1=0.8823000192642212\n",
            "vgg(\n",
            "  (feature): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (38): ReLU(inplace=True)\n",
            "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (45): ReLU(inplace=True)\n",
            "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (48): ReLU(inplace=True)\n",
            "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (51): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##測試函數(觀察模型精確度)\n"
      ],
      "metadata": {
        "id": "U0nUbcNtA_SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model):\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10('./data', train=False, download=True, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])),\n",
        "        batch_size=TEST_BATCH_SIZE, shuffle=True, **kwargs)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          if CUDA:\n",
        "              data, target = data.cuda(), target.cuda()\n",
        "          data, target = Variable(data), Variable(target)\n",
        "          output = model(data)\n",
        "          pred = output.data.max(1, keepdim=True)[1]\n",
        "          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    print('\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
        "        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
        "    return correct / float(len(test_loader.dataset))"
      ],
      "metadata": {
        "id": "Md44Lc-WBIaf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 進行剪枝\n",
        "#### 計算所有Batch Normalizaiton中的scale factor絕對值大小並排序\n",
        "#### 利用PRUNE_RATIO中取得閥值"
      ],
      "metadata": {
        "id": "srauYOD-1vSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "for m in model.modules():\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        total += m.weight.data.shape[0]\n",
        "\n",
        "bn = torch.zeros(total)\n",
        "index = 0\n",
        "for m in model.modules():\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        size = m.weight.data.shape[0]\n",
        "        bn[index:(index+size)] = m.weight.data.abs().clone()\n",
        "        index += size\n",
        "\n",
        "y, i = torch.sort(bn)\n",
        "\n",
        "\n",
        "threshold_index = int(total * PRUNE_PERCENT)\n",
        "threshold = y[threshold_index]\n"
      ],
      "metadata": {
        "id": "xgtUBaDw1uuR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##建立CONFIG，之後建立剪枝後網路時需要用到此CONFIG"
      ],
      "metadata": {
        "id": "1sy0JNTN-h3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pruned = 0\n",
        "cfg = []  #用來建立剪枝網路的CONFIG\n",
        "cfg_mask = [] #用來幫助剪枝的遮罩"
      ],
      "metadata": {
        "id": "PBklaqUZHnvp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##根據Batch Normalization Layer資訊建立CONFIG\n",
        "####1.複製Batch Normalization Layer的weight(也就是scale factor)\n",
        "####2.建立mask，大於threshold的index的值會設成1,小於threshold的值會設成0\n",
        "####3.大於threshold的index的值加總後，會是剪枝後Layer對應的輸出channel\n",
        "####4.最後得到要建立剪枝模型的CONFIG"
      ],
      "metadata": {
        "id": "66vDWd5BMmph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k, m in enumerate(model.modules()):\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        weight_copy = m.weight.data.clone()\n",
        "        mask = weight_copy.abs().gt(threshold).float().cuda()\n",
        "\n",
        "        # 注意: 需自行設計處理剩下channel數為0的情況 (e.g. 至少保留3個channel)\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "          # 1. 複製 Batch Normalization Layer 的 weight\n",
        "          weight_copy = m.weight.data.clone()\n",
        "\n",
        "          # 2. 建立 mask，大於 threshold 的設為 1，小於 threshold 的設為 0\n",
        "          mask = weight_copy.abs().gt(threshold).float().cuda()\n",
        "\n",
        "        # 確保每層至少保留 3 個通道\n",
        "        if torch.sum(mask) < 3:\n",
        "            _, top_indices = torch.topk(weight_copy.abs(), 3)  # 取得絕對值最大的前 3 個通道的索引\n",
        "            mask[top_indices] = 1.0  # 保留這 3 個通道\n",
        "\n",
        "        # 計算剪枝的通道數量並更新總計\n",
        "        pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
        "        cfg.append(int(torch.sum(mask)))\n",
        "        cfg_mask.append(mask.clone())\n",
        "        print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
        "            format(k, mask.shape[0], int(torch.sum(mask))))\n",
        "    elif isinstance(m, nn.MaxPool2d):\n",
        "        cfg.append('M')\n",
        "\n",
        "pruned_ratio = pruned/total\n",
        "\n",
        "print(f'PRUNE RATIO={pruned_ratio}')\n",
        "print('PREPROCESSING SUCCESSFUL!')\n",
        "\n",
        "print(cfg)\n"
      ],
      "metadata": {
        "id": "10ilGgoZ1SR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3610a88c-afbc-42c0-bd02-24abdeb35ec9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer index: 3 \t total channel: 64 \t remaining channel: 21\n",
            "layer index: 6 \t total channel: 64 \t remaining channel: 43\n",
            "layer index: 10 \t total channel: 128 \t remaining channel: 61\n",
            "layer index: 13 \t total channel: 128 \t remaining channel: 66\n",
            "layer index: 17 \t total channel: 256 \t remaining channel: 81\n",
            "layer index: 20 \t total channel: 256 \t remaining channel: 56\n",
            "layer index: 23 \t total channel: 256 \t remaining channel: 43\n",
            "layer index: 26 \t total channel: 256 \t remaining channel: 38\n",
            "layer index: 30 \t total channel: 512 \t remaining channel: 26\n",
            "layer index: 33 \t total channel: 512 \t remaining channel: 17\n",
            "layer index: 36 \t total channel: 512 \t remaining channel: 15\n",
            "layer index: 39 \t total channel: 512 \t remaining channel: 22\n",
            "layer index: 43 \t total channel: 512 \t remaining channel: 12\n",
            "layer index: 46 \t total channel: 512 \t remaining channel: 12\n",
            "layer index: 49 \t total channel: 512 \t remaining channel: 19\n",
            "layer index: 52 \t total channel: 512 \t remaining channel: 18\n",
            "PRUNE RATIO=0.9000726938247681\n",
            "PREPROCESSING SUCCESSFUL!\n",
            "[21, 43, 'M', 61, 66, 'M', 81, 56, 43, 38, 'M', 26, 17, 15, 22, 'M', 12, 12, 19, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###建立剪枝模型"
      ],
      "metadata": {
        "id": "_ha2BuBl1ifM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newmodel = vgg(cfg=cfg)\n",
        "newmodel.cuda()"
      ],
      "metadata": {
        "id": "SlWNdj2f1nWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5de382-b4b7-4626-ffb8-2f1cd0b945a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "vgg(\n",
              "  (feature): Sequential(\n",
              "    (0): Conv2d(3, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(21, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(43, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (8): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(61, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (11): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(66, 81, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (15): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(81, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (18): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(56, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (21): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(43, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (24): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (27): Conv2d(38, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (28): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(26, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (31): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): Conv2d(17, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (34): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): Conv2d(15, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (37): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (38): ReLU(inplace=True)\n",
              "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (40): Conv2d(22, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (41): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (44): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (45): ReLU(inplace=True)\n",
              "    (46): Conv2d(12, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (47): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (48): ReLU(inplace=True)\n",
              "    (49): Conv2d(19, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (50): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (51): ReLU(inplace=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=18, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###將原本的模型權重複製到剪枝的模型\n",
        "####1.決定該層的輸入與輸出Channel\n",
        "####2.根據不同層決定要複製什麼權重\n",
        "######Batch Normalization Layer\n",
        "1.   scale factor\n",
        "2.   bias\n",
        "3.   running mean\n",
        "4.   running variance\n",
        "\n",
        "######Convolutional Layer\n",
        "1.   weight\n",
        "2.   bias\n",
        "\n",
        "######Linear Layer\n",
        "1.   weight\n",
        "2.   bias\n",
        "\n"
      ],
      "metadata": {
        "id": "ms9Usgkh1Vbe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hQcKuMDee46V"
      },
      "outputs": [],
      "source": [
        "layer_id_in_cfg = 0\n",
        "start_mask = torch.ones(3) #3為input channel(R,G,B)\n",
        "end_mask = cfg_mask[layer_id_in_cfg]\n",
        "count = 0\n",
        "for [m0, m1] in zip(model.modules(), newmodel.modules()):\n",
        "    if isinstance(m0, nn.BatchNorm2d):\n",
        "\n",
        "        # 處理剪枝後的權重\n",
        "        m0.weight.data.mul_(end_mask)\n",
        "        m0.bias.data.mul_(end_mask)\n",
        "\n",
        "        #### 找出遮罩中非零元素的index ####\n",
        "        ################################################\n",
        "        #          請填空          #\n",
        "        idx = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
        "        if idx.size == 1:\n",
        "            idx = np.resize(idx, (1,))  # 確保索引維度一致\n",
        "        ################################################\n",
        "\n",
        "\n",
        "        # 將原本模型的權重複製到剪枝模型的權重\n",
        "\n",
        "        #### 複製weight與bias ####\n",
        "        ################################################\n",
        "        #          請填空          #\n",
        "        m1.weight.data = m0.weight.data[idx.tolist()].clone()\n",
        "        m1.bias.data = m0.bias.data[idx.tolist()].clone()\n",
        "\n",
        "        ################################################\n",
        "\n",
        "\n",
        "        #### 複製running mean跟running variance ####\n",
        "        ################################################\n",
        "        #          請填空          #\n",
        "        m1.running_mean = m0.running_mean[idx.tolist()].clone()\n",
        "        m1.running_var = m0.running_var[idx.tolist()].clone()\n",
        "\n",
        "        ################################################\n",
        "\n",
        "        layer_id_in_cfg += 1\n",
        "        start_mask = end_mask.clone()\n",
        "\n",
        "        #最後一層連接層不做修改\n",
        "        if layer_id_in_cfg < len(cfg_mask):\n",
        "            end_mask = cfg_mask[layer_id_in_cfg]\n",
        "    elif isinstance(m0, nn.Conv2d):\n",
        "        # 將原本模型的捲積層權重複製到對應剪枝模型卷積層的權重\n",
        "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
        "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
        "\n",
        "        w = m0.weight.data[:, idx0, :, :].clone()\n",
        "        w = w[idx1, :, :, :].clone()\n",
        "        m1.weight.data = w.clone()\n",
        "        #m1.bias.data = m0.bias.data[idx1].clone()\n",
        "    elif isinstance(m0, nn.Linear):\n",
        "        # 參考 https://pytorch.org/docs/stable/generated/torch.nn.Linear.html 來決定該如何複製Linear Layer參數\n",
        "\n",
        "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
        "        if idx0.size == 1:\n",
        "            idx0 = np.resize(idx0, (1,))\n",
        "\n",
        "        #### 複製weight ####\n",
        "        ################################################\n",
        "        #          請填空          #\n",
        "        m1.weight.data = m0.weight.data[:, idx0.tolist()].clone()\n",
        "        ################################################\n",
        "\n",
        "\n",
        "\n",
        "        #### 複製bias ####\n",
        "        ################################################\n",
        "        #          請填空          #\n",
        "        m1.bias.data = m0.bias.data.clone()\n",
        "\n",
        "        ################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####儲存模型並印出結果\n"
      ],
      "metadata": {
        "id": "AFkMmFLo88mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()}, PRUNE_PATH)\n",
        "\n",
        "print(newmodel)\n",
        "model = newmodel\n",
        "test(newmodel)"
      ],
      "metadata": {
        "id": "cuo3HXHt9Ar-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940f7f67-7a80-4dee-ba04-c43bf504c49b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vgg(\n",
            "  (feature): Sequential(\n",
            "    (0): Conv2d(3, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(21, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(43, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (8): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(61, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (11): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(66, 81, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (15): BatchNorm2d(81, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(81, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (18): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(56, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (21): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(43, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (24): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (27): Conv2d(38, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (28): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(26, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (31): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): Conv2d(17, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (34): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): Conv2d(15, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (37): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (38): ReLU(inplace=True)\n",
            "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (40): Conv2d(22, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (41): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (44): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (45): ReLU(inplace=True)\n",
            "    (46): Conv2d(12, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (47): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (48): ReLU(inplace=True)\n",
            "    (49): Conv2d(19, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (50): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (51): ReLU(inplace=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=18, out_features=10, bias=True)\n",
            ")\n",
            "Files already downloaded and verified\n",
            "\n",
            "Test set: Accuracy: 2615/10000 (26.1%)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2615)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}